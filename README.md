# ðŸ”ŠðŸ”ŠSpeech to Image ðŸ“· Generation
Realtime Audio to Image Generation

This is an end to end pipeline for Multilingual Speech to Image Generation
## The Models Used are: 

### 1) Whisper Model : 
Whisper is an automatic speech recognition (ASR) system trained on 680,000 hours of multilingual and multitask supervised data collected from the web

![image](https://user-images.githubusercontent.com/95982431/229340460-354e39f2-9570-4b28-a518-89c59c6ff96d.png)

![image](https://user-images.githubusercontent.com/95982431/229340470-4c1698e2-639d-4871-bd66-9f2e92cbdb29.png)

### 2) Stable Diffusion Model:
Stable Diffusion is a latent text-to-image diffusion model. Trained on LAION-5B dataset
#### 2.1) Stable Diffusion V1

Uses <b>OpenAI's CLIP</b> as Text encoder 
![image](https://user-images.githubusercontent.com/95982431/229340383-9e57b323-0b23-462a-97c4-f8b531c88350.png)

#### 2.2) Stable Diffusion V2

Uses <b>OpenCLIP</b> as Text Encoder
![image](https://user-images.githubusercontent.com/95982431/229340373-a22f4b96-529e-44e0-bd59-64bbf8655bc1.png)


